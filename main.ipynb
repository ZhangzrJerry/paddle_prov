{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as partial\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>BIO_anno</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>交行14年用过，半年准备提额，却直接被降到1Ｋ，半年期间只T过一次三千，其它全部真实消费，第...</td>\n",
       "      <td>B-BANK I-BANK O O O O O O O O O O B-COMMENTS_N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>单标我有了，最近visa双标返现活动好</td>\n",
       "      <td>B-PRODUCT I-PRODUCT O O O O O O B-PRODUCT I-PR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>建设银行提额很慢的……</td>\n",
       "      <td>B-BANK I-BANK I-BANK I-BANK B-COMMENTS_N I-COM...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>我的怎么显示0.25费率，而且不管分多少期都一样费率，可惜只有69k</td>\n",
       "      <td>O O O O O O O O O O B-COMMENTS_N I-COMMENTS_N ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>利率不错，可以撸</td>\n",
       "      <td>B-COMMENTS_N I-COMMENTS_N B-COMMENTS_ADJ I-COM...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  交行14年用过，半年准备提额，却直接被降到1Ｋ，半年期间只T过一次三千，其它全部真实消费，第...   \n",
       "1                                单标我有了，最近visa双标返现活动好   \n",
       "2                                        建设银行提额很慢的……   \n",
       "3                 我的怎么显示0.25费率，而且不管分多少期都一样费率，可惜只有69k   \n",
       "4                                           利率不错，可以撸   \n",
       "\n",
       "                                            BIO_anno  class  \n",
       "0  B-BANK I-BANK O O O O O O O O O O B-COMMENTS_N...      0  \n",
       "1  B-PRODUCT I-PRODUCT O O O O O O B-PRODUCT I-PR...      1  \n",
       "2  B-BANK I-BANK I-BANK I-BANK B-COMMENTS_N I-COM...      0  \n",
       "3  O O O O O O O O O O B-COMMENTS_N I-COMMENTS_N ...      2  \n",
       "4  B-COMMENTS_N I-COMMENTS_N B-COMMENTS_ADJ I-COM...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入训练数据和测试数据\n",
    "df_train = pd.read_csv(\"train_data_public.csv\")\n",
    "df_test = pd.read_csv(\"test_public.csv\")\n",
    "df_train = df_train.drop(['id'],axis=1)\n",
    "df_test = df_test.drop(['id'],axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-08-25 22:10:28,707] [    INFO]\u001b[0m - Loading token embedding...\u001b[0m\n",
      "\u001b[32m[2022-08-25 22:11:03,845] [    INFO]\u001b[0m - Finish loading embedding vector.\u001b[0m\n",
      "\u001b[32m[2022-08-25 22:11:03,889] [    INFO]\u001b[0m - Token Embedding info:             \n",
      "Unknown index: 635963             \n",
      "Unknown token: [UNK]             \n",
      "Padding index: 635964             \n",
      "Padding token: [PAD]             \n",
      "Shape :[635965, 300]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object   type: TokenEmbedding(635965, 300, padding_idx=635964, sparse=False)             \n",
      "Unknown index: 635963             \n",
      "Unknown token: [UNK]             \n",
      "Padding index: 635964             \n",
      "Padding token: [PAD]             \n",
      "Parameter containing:\n",
      "Tensor(shape=[635965, 300], dtype=float32, place=Place(cpu), stop_gradient=False,\n",
      "       [[-0.24200200,  0.13931701,  0.07378800, ...,  0.14103900,\n",
      "          0.05592300, -0.08004800],\n",
      "        [-0.08671700,  0.07770800,  0.09515300, ...,  0.11196400,\n",
      "          0.03082200, -0.12893000],\n",
      "        [-0.11436500,  0.12201900,  0.02833000, ...,  0.11068700,\n",
      "          0.03607300, -0.13763499],\n",
      "        ...,\n",
      "        [ 0.02628800, -0.00008300, -0.00393500, ...,  0.00654000,\n",
      "          0.00024600, -0.00662600],\n",
      "        [-0.02472960, -0.01754892,  0.02292210, ..., -0.02756814,\n",
      "         -0.02185878, -0.02111119],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          0.        ,  0.        ]])\n"
     ]
    }
   ],
   "source": [
    "# 加载TokenEmbedding\n",
    "from paddlenlp.embeddings import TokenEmbedding\n",
    "\n",
    "# 初始化TokenEmbedding, 预训练embedding未下载时会自动下载并加载数据\n",
    "token_embedding = TokenEmbedding(embedding_name=\"w2v.baidu_encyclopedia.target.word-word.dim300\")\n",
    "\n",
    "# 查看token_embedding详情\n",
    "print(token_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成100.00 %"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "train_vector = []\n",
    "mark = 0\n",
    "for i in df_train['text']:\n",
    "    # 利用jieba进行分词\n",
    "    temp = jieba.lcut(i)\n",
    "    vec_temp = []\n",
    "    # word2vec\n",
    "    for j in temp:\n",
    "        vec_temp.append(token_embedding.search(j))\n",
    "    train_vector.append(vec_temp)\n",
    "    mark += 1\n",
    "    print(\"\\r完成%.2f %%\" % (mark *100 / len(df_train)), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成100.00 %"
     ]
    }
   ],
   "source": [
    "# 利用累加把词向量合成为句向量\n",
    "mark = 0\n",
    "tain_sentence = []\n",
    "for i in train_vector:\n",
    "    vec_temp = np.zeros(300)\n",
    "    for j in i:\n",
    "        vec_temp = np.add(vec_temp,np.array(j))\n",
    "    vec_temp = np.divide(vec_temp,len(i))\n",
    "    tain_sentence.append(vec_temp)\n",
    "    mark += 1\n",
    "    print(\"\\r完成%.2f %%\" % (mark *100 / len(df_train)), end=\"\")\n",
    "train_temp = np.reshape(tain_sentence,(len(tain_sentence),300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改标签值令中立为0.5\n",
    "label_trans = np.array(df_train['class'])\n",
    "label_trans = np.where(label_trans==2,0.5,label_trans)\n",
    "\n",
    "# 切分训练集和验证集\n",
    "import paddle\n",
    "ratio = 0.8\n",
    "offset = int(ratio*len(df_train))\n",
    "x_train = paddle.to_tensor(train_temp[:offset])\n",
    "y_train = paddle.to_tensor(label_trans[:offset])\n",
    "x_dev = paddle.to_tensor(train_temp[offset:])\n",
    "y_dev = paddle.to_tensor(label_trans[offset:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(paddle.io.Dataset):\n",
    "    \"\"\"\n",
    "    步骤一:继承paddle.io.Dataset类\n",
    "    \"\"\"\n",
    "    def __init__(self,feature,label):\n",
    "        \"\"\"\n",
    "        步骤二:实现构造函数,定义数据读取方式,划分训练和测试数据集\n",
    "        \"\"\"\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.features = paddle.to_tensor(feature, dtype='float32')\n",
    "        self.labels = paddle.to_tensor(label, dtype='float32')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        步骤三:实现__getitem__方法,定义指定index时如何获取数据,并返回单条数据（训练数据）\n",
    "        \"\"\"\n",
    "        feature = self.features[index]\n",
    "        label = self.labels[index]\n",
    "        return feature, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        步骤四:实现__len__方法,返回数据集总数目\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = MyDataset(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 情感分类模型\n",
    "import paddle.nn.layer\n",
    "class myNet(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(myNet, self).__init__()\n",
    "        self.l1 = paddle.nn.Linear(300,900,)\n",
    "        self.l2 = paddle.nn.Linear(900,450,)\n",
    "        self.l3 = paddle.nn.Linear(450,225,)\n",
    "        self.l4 = paddle.nn.Linear(225,15,)\n",
    "        self.l5 = paddle.nn.Linear(15,1,)\n",
    "        self.softmax = paddle.nn.layer.Softmax()\n",
    "        self.sigmoid = paddle.nn.layer.Sigmoid()\n",
    "        self.dropout = paddle.nn.layer.Dropout(0.3)\n",
    "\n",
    "    def forward(self,pred):\n",
    "        pred = self.l1(pred)\n",
    "        pred = self.dropout(pred)\n",
    "        pred = self.sigmoid(pred)\n",
    "        pred = self.l2(pred)\n",
    "        pred = self.dropout(pred)\n",
    "        pred = self.sigmoid(pred)\n",
    "        pred = self.l3(pred)\n",
    "        pred = self.sigmoid(pred)\n",
    "        pred = self.l4(pred)\n",
    "        pred = self.sigmoid(pred)\n",
    "        pred = self.l5(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle.metric import Accuracy\n",
    "\n",
    "model = paddle.Model(myNet())\n",
    "# 配置模型\n",
    "model.prepare(\n",
    "    paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()),\n",
    "    paddle.nn.L1Loss(),\n",
    "    Accuracy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\项目\\让我们荡起飞桨\\飞桨_观点提取\\main.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%A7%82%E7%82%B9%E6%8F%90%E5%8F%96/main.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 训练模型\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%A7%82%E7%82%B9%E6%8F%90%E5%8F%96/main.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%A7%82%E7%82%B9%E6%8F%90%E5%8F%96/main.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%A7%82%E7%82%B9%E6%8F%90%E5%8F%96/main.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%A7%82%E7%82%B9%E6%8F%90%E5%8F%96/main.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E9%A1%B9%E7%9B%AE/%E8%AE%A9%E6%88%91%E4%BB%AC%E8%8D%A1%E8%B5%B7%E9%A3%9E%E6%A1%A8/%E9%A3%9E%E6%A1%A8_%E8%A7%82%E7%82%B9%E6%8F%90%E5%8F%96/main.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddle\\hapi\\model.py:1767\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, train_data, eval_data, batch_size, epochs, eval_freq, log_freq, save_dir, save_freq, verbose, drop_last, shuffle, num_workers, callbacks, accumulate_grad_batches, num_iters)\u001b[0m\n\u001b[0;32m   1765\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m   1766\u001b[0m     cbks\u001b[39m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m-> 1767\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_one_epoch(train_loader, cbks, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m   1768\u001b[0m     cbks\u001b[39m.\u001b[39mon_epoch_end(epoch, logs)\n\u001b[0;32m   1770\u001b[0m     \u001b[39mif\u001b[39;00m do_eval \u001b[39mand\u001b[39;00m epoch \u001b[39m%\u001b[39m eval_freq \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddle\\hapi\\model.py:2097\u001b[0m, in \u001b[0;36mModel._run_one_epoch\u001b[1;34m(self, data_loader, callbacks, mode, logs)\u001b[0m\n\u001b[0;32m   2093\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   2094\u001b[0m     _inputs\u001b[39m.\u001b[39mappend((step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accumulate \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m\n\u001b[0;32m   2095\u001b[0m                    step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(data_loader))\n\u001b[1;32m-> 2097\u001b[0m outs \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, mode \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m_batch\u001b[39;49m\u001b[39m'\u001b[39;49m)(\u001b[39m*\u001b[39;49m_inputs)\n\u001b[0;32m   2099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metrics \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss:\n\u001b[0;32m   2100\u001b[0m     metrics \u001b[39m=\u001b[39m [[l[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m outs[\u001b[39m0\u001b[39m]]]\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddle\\hapi\\model.py:1093\u001b[0m, in \u001b[0;36mModel.train_batch\u001b[1;34m(self, inputs, labels, update)\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_batch\u001b[39m(\u001b[39mself\u001b[39m, inputs, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, update\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1046\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m \u001b[39m    Run one training step on one batch of data. And using `update` indicates\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[39m    whether optimizer update gradients computing by this batch.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[39m          print(loss)\u001b[39;00m\n\u001b[0;32m   1092\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1093\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_adapter\u001b[39m.\u001b[39;49mtrain_batch(inputs, labels, update)\n\u001b[0;32m   1094\u001b[0m     \u001b[39mif\u001b[39;00m fluid\u001b[39m.\u001b[39m_non_static_mode() \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_info \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1095\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inputs()\n",
      "File \u001b[1;32mc:\\Users\\Administer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\paddle\\hapi\\model.py:730\u001b[0m, in \u001b[0;36mDynamicGraphAdapter.train_batch\u001b[1;34m(self, inputs, labels, update)\u001b[0m\n\u001b[0;32m    726\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    727\u001b[0m         outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39mforward(\n\u001b[0;32m    728\u001b[0m             \u001b[39m*\u001b[39m[to_variable(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m inputs])\n\u001b[1;32m--> 730\u001b[0m losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39m_loss(\u001b[39m*\u001b[39m(to_list(outputs) \u001b[39m+\u001b[39;49m labels))\n\u001b[0;32m    731\u001b[0m losses \u001b[39m=\u001b[39m to_list(losses)\n\u001b[0;32m    732\u001b[0m final_loss \u001b[39m=\u001b[39m fluid\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39msum(losses)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'list'"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "model.fit(train_dataset,\n",
    "        epochs=2,\n",
    "        batch_size=64,\n",
    "        verbose=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(paddle.to_tensor(train_temp[0]))\n",
    "# train_temp[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "538aa17ce8a0584118ce85ff12bec826ccfc3555eae6360211bc5883b796f561"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
